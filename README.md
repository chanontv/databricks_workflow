# databricks_workflow

## Workflow
   - Set up and configured the Databricks workspace and compute resources.
   <img src="img/create_workspaces.jpg" />
   <img src="img/create_compute.jpg" />
   - Generate a new token on Databricks and add it to the GitHub repository secrets.
   <img src="img/repository_secrets.jpg" />
   - Retrieved datasets from Kaggle and performed data cleaning using PySpark.
   <img src="img/notebook_workspace.jpg" />
   - Designed and implemented a CI/CD pipeline for deployment processes.
   <img src="img/git_actions.jpg" />
   - Automated job scheduling and execution within Databricks. 
   <img src="img/jobs.jpg" />
   - Uploaded processed results to Google Cloud Storage (GCS).
   <img src="img/gcs.jpg" />

## Dataset
https://www.kaggle.com/datasets/sp1thas/book-depository-dataset