# databricks_workflow

## Workflow
   - Set up and configured the Databricks workspace and compute resources.
   <img src="img/create_workspaces.JPG" />
   <img src="img/create_compute.JPG" />
   - Generate a new token on Databricks and add it to the GitHub repository secrets.
   <img src="img/repository_secrets.JPG" />
   - Retrieved datasets from Kaggle and performed data cleaning using PySpark.
   <img src="img/notebook_workspace.JPG" />
   - Designed and implemented a CI/CD pipeline for deployment processes.
   <img src="img/git_actions.JPG" />
   - Automated job scheduling and execution within Databricks. 
   <img src="img/job.JPG" />
   - Uploaded processed results to Google Cloud Storage (GCS).
   <img src="img/gcs.JPG" />

## Dataset
https://www.kaggle.com/datasets/sp1thas/book-depository-dataset